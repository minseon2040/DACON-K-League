{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QKhScyWaSO-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from catboost import CatBoostRegressor\n",
        "import lightgbm as lgb\n",
        "from feature_engineering.dataset import build_dataset\n",
        "from feature_engineering.features import FEATURE_CANDIDATES, CAT_CANDIDATES, SORT_KEYS, DROP_COLS\n",
        "from model.utils import metric\n",
        "\n",
        "\n",
        "class Config:\n",
        "    SEED = 42\n",
        "    N_FOLDS = 5\n",
        "    CLIP_X = (0, 105)\n",
        "    CLIP_Y = (0, 68)\n",
        "\n",
        "    # Base 모델\n",
        "    BASE_PARAMS = {\n",
        "        'depth' :10,\n",
        "        'learning_rate' : 0.0222,\n",
        "        'l2_leaf_reg' : 2.80,\n",
        "        'rsm' : 0.6716,\n",
        "        'bagging_temperature' : 0.121,\n",
        "        'iterations' : 6000,\n",
        "        'early_stopping_rounds' : 200\n",
        "    }\n",
        "\n",
        "    # Fixer 모델\n",
        "    FIXER_PARAMS = {\n",
        "        'depth' : 7,\n",
        "        'learning_rate' : 0.0339,\n",
        "        'l2_leaf_reg' : 26.74,\n",
        "        'rsm' : 0.9103,\n",
        "        'bagging_temperature' : 0.4276,\n",
        "        'loss_function' : 'MAE',\n",
        "        'early_stopping_rounds' : 250\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoeEc0prTu1c"
      },
      "outputs": [],
      "source": [
        "# 1) CatBoost 파이프라인 (Base + LongSwap + Fixer)\n",
        "#    - 반환을 voting에 쓰기 좋게 고정\n",
        "\n",
        "def train_long_model(X_train, y_dx, y_dy, cat_features):\n",
        "    # long 정의 (OOF 기준과 동일)\n",
        "    pass_dist = np.sqrt(y_dx**2 + y_dy**2)\n",
        "    mask_long = pass_dist >= 35\n",
        "\n",
        "    X_long = X_train[mask_long]\n",
        "    y_dx_long = y_dx[mask_long]\n",
        "    y_dy_long = y_dy[mask_long]\n",
        "\n",
        "    print(f\"[LONG] samples: {len(X_long)}\")\n",
        "\n",
        "    LONG_PARAMS = {\n",
        "        'depth': 7,\n",
        "        'learning_rate': 0.03,\n",
        "        'iterations': 1200,\n",
        "        'loss_function': 'RMSE',\n",
        "        'early_stopping_rounds': 100,\n",
        "        'random_seed': 42,\n",
        "        'verbose': 200\n",
        "    }\n",
        "\n",
        "    model_dx = CatBoostRegressor(**LONG_PARAMS)\n",
        "    model_dy = CatBoostRegressor(**LONG_PARAMS)\n",
        "\n",
        "    model_dx.fit(X_long, y_dx_long, cat_features=cat_features)\n",
        "    model_dy.fit(X_long, y_dy_long, cat_features=cat_features)\n",
        "\n",
        "    return model_dx, model_dy\n",
        "\n",
        "def train_residual_pipeline_cat(\n",
        "    X_train, y_dx, y_dy, X_test, groups, cat_features,\n",
        "    long_threshold=35.0, min_long_samples=50, verbose=200\n",
        "):\n",
        "    gkf = GroupKFold(n_splits=Config.N_FOLDS)\n",
        "\n",
        "    # OOF\n",
        "    oof_base_dx = np.zeros(len(X_train), dtype=np.float32)\n",
        "    oof_base_dy = np.zeros(len(X_train), dtype=np.float32)\n",
        "    oof_fix_dx  = np.zeros(len(X_train), dtype=np.float32)\n",
        "    oof_fix_dy  = np.zeros(len(X_train), dtype=np.float32)\n",
        "\n",
        "    # TEST (분리)\n",
        "    test_base_dx = np.zeros(len(X_test), dtype=np.float32)\n",
        "    test_base_dy = np.zeros(len(X_test), dtype=np.float32)\n",
        "    test_fix_dx  = np.zeros(len(X_test), dtype=np.float32)\n",
        "    test_fix_dy  = np.zeros(len(X_test), dtype=np.float32)\n",
        "\n",
        "    # 중요도\n",
        "    fi_df = pd.DataFrame(index=X_train.columns)\n",
        "    fi_df[\"importance\"] = 0.0\n",
        "\n",
        "    print(\"\\n===== [CatBoost] 5-Fold Training (Base + LongSwap + Fixer) =====\")\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in enumerate(gkf.split(X_train, y_dx, groups=groups), 1):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "\n",
        "        X_tr = X_train.iloc[tr_idx]\n",
        "        X_va = X_train.iloc[va_idx]\n",
        "\n",
        "        # 1) Base\n",
        "        model_dx = CatBoostRegressor(**Config.BASE_PARAMS)\n",
        "        model_dy = CatBoostRegressor(**Config.BASE_PARAMS)\n",
        "\n",
        "        model_dx.fit(\n",
        "            X_tr, y_dx[tr_idx],\n",
        "            eval_set=[(X_va, y_dx[va_idx])],\n",
        "            cat_features=cat_features, verbose=verbose\n",
        "        )\n",
        "        model_dy.fit(\n",
        "            X_tr, y_dy[tr_idx],\n",
        "            eval_set=[(X_va, y_dy[va_idx])],\n",
        "            cat_features=cat_features, verbose=verbose\n",
        "        )\n",
        "\n",
        "        # 2) long 마스크(Train/Val은 true dist)\n",
        "        tr_dist = np.sqrt(y_dx[tr_idx]**2 + y_dy[tr_idx]**2)\n",
        "        va_dist = np.sqrt(y_dx[va_idx]**2 + y_dy[va_idx]**2)\n",
        "\n",
        "        mask_long_tr = (tr_dist >= long_threshold)\n",
        "        mask_long_va = (va_dist >= long_threshold)\n",
        "\n",
        "        if mask_long_tr.sum() >= min_long_samples:\n",
        "            long_dx_model, long_dy_model = train_long_model(\n",
        "                X_tr[mask_long_tr],\n",
        "                y_dx[tr_idx][mask_long_tr],\n",
        "                y_dy[tr_idx][mask_long_tr],\n",
        "                cat_features\n",
        "            )\n",
        "        else:\n",
        "            long_dx_model, long_dy_model = None, None\n",
        "            print(f\"[Fold {fold}] long samples 부족({mask_long_tr.sum()}), long swap 스킵\")\n",
        "\n",
        "        # 3) OOF base pred\n",
        "        val_dx = model_dx.predict(X_va).astype(np.float32)\n",
        "        val_dy = model_dy.predict(X_va).astype(np.float32)\n",
        "\n",
        "        # 4) OOF long swap (val은 true dist 기준)\n",
        "        if long_dx_model is not None and mask_long_va.sum() > 0:\n",
        "            val_dx[mask_long_va] = long_dx_model.predict(X_va[mask_long_va]).astype(np.float32)\n",
        "            val_dy[mask_long_va] = long_dy_model.predict(X_va[mask_long_va]).astype(np.float32)\n",
        "\n",
        "        # 5) OOF 저장\n",
        "        oof_base_dx[va_idx] = val_dx\n",
        "        oof_base_dy[va_idx] = val_dy\n",
        "\n",
        "        # 6) TEST base pred + TEST long swap(예측거리 기준)\n",
        "        test_dx_fold = model_dx.predict(X_test).astype(np.float32)\n",
        "        test_dy_fold = model_dy.predict(X_test).astype(np.float32)\n",
        "\n",
        "        if long_dx_model is not None:\n",
        "            test_dist_pred = np.sqrt(test_dx_fold**2 + test_dy_fold**2)\n",
        "            mask_long_te = (test_dist_pred >= long_threshold)\n",
        "            if mask_long_te.sum() > 0:\n",
        "                test_dx_fold[mask_long_te] = long_dx_model.predict(X_test[mask_long_te]).astype(np.float32)\n",
        "                test_dy_fold[mask_long_te] = long_dy_model.predict(X_test[mask_long_te]).astype(np.float32)\n",
        "\n",
        "        test_base_dx += test_dx_fold / Config.N_FOLDS\n",
        "        test_base_dy += test_dy_fold / Config.N_FOLDS\n",
        "\n",
        "        # 중요도\n",
        "        fi_df[\"importance\"] += model_dx.get_feature_importance() / Config.N_FOLDS\n",
        "\n",
        "        # 7) Fixer (잔차)\n",
        "        train_dx_pred = model_dx.predict(X_tr).astype(np.float32)\n",
        "        train_dy_pred = model_dy.predict(X_tr).astype(np.float32)\n",
        "\n",
        "        resid_dx_tr = y_dx[tr_idx] - train_dx_pred\n",
        "        resid_dy_tr = y_dy[tr_idx] - train_dy_pred\n",
        "\n",
        "        resid_dx_va = y_dx[va_idx] - val_dx\n",
        "        resid_dy_va = y_dy[va_idx] - val_dy\n",
        "\n",
        "        fixer_dx = CatBoostRegressor(**Config.FIXER_PARAMS)\n",
        "        fixer_dy = CatBoostRegressor(**Config.FIXER_PARAMS)\n",
        "\n",
        "        fixer_dx.fit(\n",
        "            X_tr, resid_dx_tr,\n",
        "            eval_set=[(X_va, resid_dx_va)],\n",
        "            cat_features=cat_features, verbose=verbose\n",
        "        )\n",
        "        fixer_dy.fit(\n",
        "            X_tr, resid_dy_tr,\n",
        "            eval_set=[(X_va, resid_dy_va)],\n",
        "            cat_features=cat_features, verbose=verbose\n",
        "        )\n",
        "\n",
        "        oof_fix_dx[va_idx] = fixer_dx.predict(X_va).astype(np.float32)\n",
        "        oof_fix_dy[va_idx] = fixer_dy.predict(X_va).astype(np.float32)\n",
        "\n",
        "        test_fix_dx += fixer_dx.predict(X_test).astype(np.float32) / Config.N_FOLDS\n",
        "        test_fix_dy += fixer_dy.predict(X_test).astype(np.float32) / Config.N_FOLDS\n",
        "\n",
        "    # 최종 합\n",
        "    oof_pred_dx = oof_base_dx + oof_fix_dx\n",
        "    oof_pred_dy = oof_base_dy + oof_fix_dy\n",
        "\n",
        "    test_pred_dx = test_base_dx + test_fix_dx\n",
        "    test_pred_dy = test_base_dy + test_fix_dy\n",
        "\n",
        "    oof_df = X_train.copy()\n",
        "    oof_df[\"true_dx\"] = y_dx\n",
        "    oof_df[\"true_dy\"] = y_dy\n",
        "    oof_df[\"pred_dx\"] = oof_pred_dx\n",
        "    oof_df[\"pred_dy\"] = oof_pred_dy\n",
        "    oof_df[\"pass_dist\"] = np.sqrt(oof_df[\"true_dx\"]**2 + oof_df[\"true_dy\"]**2)\n",
        "\n",
        "    score = metric(y_dx, y_dy, oof_pred_dx, oof_pred_dy)\n",
        "    print(f\"\\n[CatBoost] OOF: {score:.4f}m\")\n",
        "\n",
        "    return oof_pred_dx, oof_pred_dy, test_pred_dx, test_pred_dy, fi_df, oof_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Zh81tkxkbc2"
      },
      "outputs": [],
      "source": [
        "# 1) (LGBM) 인코딩: 범주형은 __NA__로 처리 후 factorize\n",
        "#    수치형만 -999로 결측 처리\n",
        "\n",
        "def encode_for_lgbm(X_train, X_test, cat_cols, make_category_dtype=True):\n",
        "    Xtr = X_train.copy()\n",
        "    Xte = X_test.copy()\n",
        "    ntr = len(Xtr)\n",
        "\n",
        "    cat_cols = [c for c in cat_cols if c in Xtr.columns]\n",
        "\n",
        "    # 범주형: __NA__ -> factorize (train+test together)\n",
        "    for c in cat_cols:\n",
        "        combined = pd.concat([Xtr[c], Xte[c]], axis=0).astype(\"object\").fillna(\"__NA__\")\n",
        "        codes, _ = pd.factorize(combined, sort=False)\n",
        "\n",
        "        Xtr[c] = pd.Series(codes[:ntr], index=Xtr.index).astype(\"int32\")\n",
        "        Xte[c] = pd.Series(codes[ntr:], index=Xte.index).astype(\"int32\")\n",
        "\n",
        "        if make_category_dtype:\n",
        "            Xtr[c] = Xtr[c].astype(\"category\")\n",
        "            Xte[c] = Xte[c].astype(\"category\")\n",
        "\n",
        "    # 수치형: inf/NaN -> -999\n",
        "    num_cols = [c for c in Xtr.columns if c not in cat_cols]\n",
        "    if num_cols:\n",
        "        Xtr[num_cols] = Xtr[num_cols].replace([np.inf, -np.inf], np.nan).fillna(-999)\n",
        "        Xte[num_cols] = Xte[num_cols].replace([np.inf, -np.inf], np.nan).fillna(-999)\n",
        "\n",
        "    return Xtr, Xte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFQB3JukzNvx"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# 3) LightGBM: A1 잔차 Fixer 2-stage + A2 LongSwap\n",
        "def run_lgbm_oof_residual_longswap(\n",
        "    X_train, y_dx, y_dy, X_test, groups, cat_cols,\n",
        "    long_threshold=35.0, min_long_samples=50,\n",
        "    make_category_dtype=True,\n",
        "    base_params=None, fixer_params=None,\n",
        "    num_boost_round=6000, early_stopping_rounds=200, verbose_eval=200\n",
        "):\n",
        "    Xtr, Xte = encode_for_lgbm(X_train, X_test, cat_cols, make_category_dtype=make_category_dtype)\n",
        "    gkf = GroupKFold(n_splits=Config.N_FOLDS)\n",
        "    cat_feats_present = [c for c in cat_cols if c in Xtr.columns]\n",
        "\n",
        "\n",
        "    # 기본 파라미터\n",
        "    if base_params is None:\n",
        "        base_params = dict(\n",
        "            objective=\"huber\",\n",
        "            alpha=0.9,\n",
        "            metric=\"rmse\",\n",
        "            learning_rate=0.03,\n",
        "            num_leaves=64,\n",
        "            feature_fraction=0.8,\n",
        "            bagging_fraction=0.8,\n",
        "            bagging_freq=1,\n",
        "            min_data_in_leaf=50,\n",
        "            lambda_l2=5.0,\n",
        "            seed=Config.SEED if hasattr(Config, \"SEED\") else 42,\n",
        "            verbosity=-1\n",
        "        )\n",
        "    if fixer_params is None:\n",
        "        fixer_params = dict(\n",
        "            objective=\"regression_l1\",  # 잔차는 L1 안정적\n",
        "            metric=\"rmse\",\n",
        "            learning_rate=0.03,\n",
        "            num_leaves=48,\n",
        "            feature_fraction=0.8,\n",
        "            bagging_fraction=0.8,\n",
        "            bagging_freq=1,\n",
        "            min_data_in_leaf=80,\n",
        "            lambda_l2=8.0,\n",
        "            seed=Config.SEED if hasattr(Config, \"SEED\") else 42,\n",
        "            verbosity=-1\n",
        "        )\n",
        "\n",
        "    # OOF/TEST 저장소\n",
        "    oof_base_dx = np.zeros(len(Xtr), dtype=np.float32)\n",
        "    oof_base_dy = np.zeros(len(Xtr), dtype=np.float32)\n",
        "    oof_fix_dx  = np.zeros(len(Xtr), dtype=np.float32)\n",
        "    oof_fix_dy  = np.zeros(len(Xtr), dtype=np.float32)\n",
        "\n",
        "    test_base_dx = np.zeros(len(Xte), dtype=np.float32)\n",
        "    test_base_dy = np.zeros(len(Xte), dtype=np.float32)\n",
        "    test_fix_dx  = np.zeros(len(Xte), dtype=np.float32)\n",
        "    test_fix_dy  = np.zeros(len(Xte), dtype=np.float32)\n",
        "\n",
        "    print(\"\\n===== [LightGBM] 5-Fold Training (Base + Fixer + LongSwap) =====\")\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in enumerate(gkf.split(Xtr, y_dx, groups=groups), 1):\n",
        "        print(f\"\\n[LGBM] Fold {fold}\")\n",
        "\n",
        "        X_tr, X_va = Xtr.iloc[tr_idx], Xtr.iloc[va_idx]\n",
        "        ydx_tr, ydx_va = y_dx[tr_idx], y_dx[va_idx]\n",
        "        ydy_tr, ydy_va = y_dy[tr_idx], y_dy[va_idx]\n",
        "\n",
        "        # ---------- Base dx ----------\n",
        "        dtrain_dx = lgb.Dataset(X_tr, label=ydx_tr, categorical_feature=cat_feats_present, free_raw_data=False)\n",
        "        dvalid_dx = lgb.Dataset(X_va, label=ydx_va, categorical_feature=cat_feats_present, free_raw_data=False)\n",
        "\n",
        "        base_dx = lgb.train(\n",
        "            base_params, dtrain_dx, num_boost_round=num_boost_round, valid_sets=[dvalid_dx],\n",
        "            callbacks=[lgb.early_stopping(early_stopping_rounds, verbose=True),\n",
        "                       lgb.log_evaluation(period=verbose_eval)]\n",
        "        )\n",
        "\n",
        "        # ---------- Base dy ----------\n",
        "        dtrain_dy = lgb.Dataset(X_tr, label=ydy_tr, categorical_feature=cat_feats_present, free_raw_data=False)\n",
        "        dvalid_dy = lgb.Dataset(X_va, label=ydy_va, categorical_feature=cat_feats_present, free_raw_data=False)\n",
        "\n",
        "        base_dy = lgb.train(\n",
        "            base_params, dtrain_dy, num_boost_round=num_boost_round, valid_sets=[dvalid_dy],\n",
        "            callbacks=[lgb.early_stopping(early_stopping_rounds, verbose=True),\n",
        "                       lgb.log_evaluation(period=verbose_eval)]\n",
        "        )\n",
        "\n",
        "        # base pred (val)\n",
        "        val_base_dx = base_dx.predict(X_va, num_iteration=base_dx.best_iteration).astype(np.float32)\n",
        "        val_base_dy = base_dy.predict(X_va, num_iteration=base_dy.best_iteration).astype(np.float32)\n",
        "        oof_base_dx[va_idx] = val_base_dx\n",
        "        oof_base_dy[va_idx] = val_base_dy\n",
        "\n",
        "        # base pred (test fold)\n",
        "        te_base_dx = base_dx.predict(Xte, num_iteration=base_dx.best_iteration).astype(np.float32)\n",
        "        te_base_dy = base_dy.predict(Xte, num_iteration=base_dy.best_iteration).astype(np.float32)\n",
        "        test_base_dx += te_base_dx / Config.N_FOLDS\n",
        "        test_base_dy += te_base_dy / Config.N_FOLDS\n",
        "\n",
        "        # ---------- Fixer residual targets ----------\n",
        "        tr_base_dx = base_dx.predict(X_tr, num_iteration=base_dx.best_iteration).astype(np.float32)\n",
        "        tr_base_dy = base_dy.predict(X_tr, num_iteration=base_dy.best_iteration).astype(np.float32)\n",
        "\n",
        "        resid_dx_tr = (ydx_tr - tr_base_dx).astype(np.float32)\n",
        "        resid_dy_tr = (ydy_tr - tr_base_dy).astype(np.float32)\n",
        "\n",
        "        resid_dx_va_true = (ydx_va - val_base_dx).astype(np.float32)\n",
        "        resid_dy_va_true = (ydy_va - val_base_dy).astype(np.float32)\n",
        "\n",
        "        # ---------- Fixer dx ----------\n",
        "        ftrain_dx = lgb.Dataset(X_tr, label=resid_dx_tr, categorical_feature=cat_feats_present, free_raw_data=False)\n",
        "        fvalid_dx = lgb.Dataset(X_va, label=resid_dx_va_true, categorical_feature=cat_feats_present, free_raw_data=False)\n",
        "\n",
        "        fix_dx = lgb.train(\n",
        "            fixer_params, ftrain_dx, num_boost_round=num_boost_round, valid_sets=[fvalid_dx],\n",
        "            callbacks=[lgb.early_stopping(early_stopping_rounds, verbose=True),\n",
        "                       lgb.log_evaluation(period=verbose_eval)]\n",
        "        )\n",
        "\n",
        "        # ---------- Fixer dy ----------\n",
        "        ftrain_dy = lgb.Dataset(X_tr, label=resid_dy_tr, categorical_feature=cat_feats_present, free_raw_data=False)\n",
        "        fvalid_dy = lgb.Dataset(X_va, label=resid_dy_va_true, categorical_feature=cat_feats_present, free_raw_data=False)\n",
        "\n",
        "        fix_dy = lgb.train(\n",
        "            fixer_params, ftrain_dy, num_boost_round=num_boost_round, valid_sets=[fvalid_dy],\n",
        "            callbacks=[lgb.early_stopping(early_stopping_rounds, verbose=True),\n",
        "                       lgb.log_evaluation(period=verbose_eval)]\n",
        "        )\n",
        "\n",
        "        # fixer pred\n",
        "        val_fix_dx = fix_dx.predict(X_va, num_iteration=fix_dx.best_iteration).astype(np.float32)\n",
        "        val_fix_dy = fix_dy.predict(X_va, num_iteration=fix_dy.best_iteration).astype(np.float32)\n",
        "        oof_fix_dx[va_idx] = val_fix_dx\n",
        "        oof_fix_dy[va_idx] = val_fix_dy\n",
        "\n",
        "        te_fix_dx = fix_dx.predict(Xte, num_iteration=fix_dx.best_iteration).astype(np.float32)\n",
        "        te_fix_dy = fix_dy.predict(Xte, num_iteration=fix_dy.best_iteration).astype(np.float32)\n",
        "        test_fix_dx += te_fix_dx / Config.N_FOLDS\n",
        "        test_fix_dy += te_fix_dy / Config.N_FOLDS\n",
        "\n",
        "    # base+fixer 합\n",
        "    oof_dx = oof_base_dx + oof_fix_dx\n",
        "    oof_dy = oof_base_dy + oof_fix_dy\n",
        "    test_dx = test_base_dx + test_fix_dx\n",
        "    test_dy = test_base_dy + test_fix_dy\n",
        "\n",
        "    # ---------- A2) LongSwap ----------\n",
        "    # OOF: true dist 기준으로 long 구간 swap (train_epi의 true dist 필요)\n",
        "    true_dist = np.sqrt(y_dx**2 + y_dy**2)\n",
        "    mask_long_oof = (true_dist >= long_threshold)\n",
        "\n",
        "    # long 모델 학습은 \"전체 train의 long\"으로 한번 실행\n",
        "    if mask_long_oof.sum() >= min_long_samples:\n",
        "        # long 전용은 base+fixer가 아닌, \"별도 long 전용 base\"로 가는 게 보통 더 안정적\n",
        "        # 여기서는 간단히 long 전용 dx/dy를 따로 학습\n",
        "        # (다만 cat_cols는 이미 인코딩된 Xtr/Xte를 쓰므로 cat_feats_present 그대로)\n",
        "        import lightgbm as lgb\n",
        "\n",
        "        X_long = Xtr[mask_long_oof]\n",
        "        ydx_long = y_dx[mask_long_oof]\n",
        "        ydy_long = y_dy[mask_long_oof]\n",
        "\n",
        "        dlong_dx = lgb.Dataset(X_long, label=ydx_long, categorical_feature=cat_feats_present, free_raw_data=False)\n",
        "        dlong_dy = lgb.Dataset(X_long, label=ydy_long, categorical_feature=cat_feats_present, free_raw_data=False)\n",
        "\n",
        "        long_params = dict(base_params)\n",
        "        long_params.update({\"learning_rate\": 0.05, \"num_leaves\": 96, \"min_data_in_leaf\": 30})\n",
        "\n",
        "        long_dx = lgb.train(long_params, dlong_dx, num_boost_round=1500, valid_sets=None)\n",
        "        long_dy = lgb.train(long_params, dlong_dy, num_boost_round=1500, valid_sets=None)\n",
        "\n",
        "        # OOF long swap (true dist mask)\n",
        "        if mask_long_oof.sum() > 0:\n",
        "            oof_dx_swap = oof_dx.copy()\n",
        "            oof_dy_swap = oof_dy.copy()\n",
        "            oof_dx_swap[mask_long_oof] = long_dx.predict(Xtr.iloc[np.where(mask_long_oof)[0]]).astype(np.float32)\n",
        "            oof_dy_swap[mask_long_oof] = long_dy.predict(Xtr.iloc[np.where(mask_long_oof)[0]]).astype(np.float32)\n",
        "            oof_dx, oof_dy = oof_dx_swap, oof_dy_swap\n",
        "\n",
        "        # TEST long swap (pred dist 기준)\n",
        "        pred_dist_test = np.sqrt(test_dx**2 + test_dy**2)\n",
        "        mask_long_te = (pred_dist_test >= long_threshold)\n",
        "        if mask_long_te.sum() > 0:\n",
        "            test_dx_swap = test_dx.copy()\n",
        "            test_dy_swap = test_dy.copy()\n",
        "            test_dx_swap[mask_long_te] = long_dx.predict(Xte.iloc[np.where(mask_long_te)[0]]).astype(np.float32)\n",
        "            test_dy_swap[mask_long_te] = long_dy.predict(Xte.iloc[np.where(mask_long_te)[0]]).astype(np.float32)\n",
        "            test_dx, test_dy = test_dx_swap, test_dy_swap\n",
        "\n",
        "    oof_score = metric(y_dx, y_dy, oof_dx, oof_dy)\n",
        "    print(f\"\\n[LightGBM] OOF: {oof_score:.4f}m\")\n",
        "\n",
        "    return oof_dx, oof_dy, test_dx, test_dy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ey5LRf4d4eIB"
      },
      "outputs": [],
      "source": [
        "# 1) MLP 구조 정의\n",
        "class PassMLP(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(),\n",
        "            nn.Linear(128, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 2)  # dx, dy\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "# 2) 유클리디안 Loss (L2 거리 직접 최적화)\n",
        "class EuclideanLoss(nn.Module):\n",
        "    def forward(self, pred, target):\n",
        "        return torch.mean(torch.sqrt(torch.sum((pred - target) ** 2, dim=1) + 1e-7))\n",
        "\n",
        "\n",
        "# 3) 학습 함수 (OOF/TEST 생성)\n",
        "def run_mlp_pipeline(\n",
        "    X_train, y_dx, y_dy, X_test, groups, cat_cols,\n",
        "    n_splits=5, epochs=60, batch_size=256, lr=0.002,\n",
        "    seed=42, save_dir=\"models\", device=None\n",
        "):\n",
        "    # ----- 재현성 -----\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # ----- device -----\n",
        "    if device is None:\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # ----- 폴더 생성 (저장 에러 방지) -----\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # [수정] 범주형 피처를 숫자로 변환 (Train/Test 합쳐서 factorize)\n",
        "    Xtr = X_train.copy()\n",
        "    Xte = X_test.copy()\n",
        "\n",
        "    for c in cat_cols:\n",
        "        if c in Xtr.columns:\n",
        "            combined = pd.concat([Xtr[c], Xte[c]], axis=0).astype(\"object\").fillna(\"__NA__\")\n",
        "            codes, _ = pd.factorize(combined, sort=False)\n",
        "            Xtr[c] = codes[:len(Xtr)].astype(np.int64)\n",
        "            Xte[c] = codes[len(Xtr):].astype(np.int64)\n",
        "\n",
        "    # StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    Xtr_s = scaler.fit_transform(Xtr.fillna(0))\n",
        "    Xte_s = scaler.transform(Xte.fillna(0))\n",
        "\n",
        "    # OOF/TEST 저장소\n",
        "    oof_dx = np.zeros(len(Xtr_s), dtype=np.float32)\n",
        "    oof_dy = np.zeros(len(Xtr_s), dtype=np.float32)\n",
        "    test_dx = np.zeros(len(Xte_s), dtype=np.float32)\n",
        "    test_dy = np.zeros(len(Xte_s), dtype=np.float32)\n",
        "\n",
        "    gkf = GroupKFold(n_splits=n_splits)\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in enumerate(gkf.split(Xtr_s, y_dx, groups=groups), 1):\n",
        "        # dataset/loader\n",
        "        X_tr = torch.tensor(Xtr_s[tr_idx], dtype=torch.float32)\n",
        "        y_tr = torch.tensor(np.column_stack([y_dx[tr_idx], y_dy[tr_idx]]), dtype=torch.float32)\n",
        "        train_ds = TensorDataset(X_tr, y_tr)\n",
        "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        # model\n",
        "        model = PassMLP(Xtr_s.shape[1]).to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "        criterion = EuclideanLoss()\n",
        "\n",
        "        # train\n",
        "        model.train()\n",
        "        for epoch in range(epochs):\n",
        "            for bx, by in train_loader:\n",
        "                bx, by = bx.to(device), by.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                pred = model(bx)\n",
        "                loss = criterion(pred, by)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        # 모델 저장\n",
        "        torch.save(model.state_dict(), os.path.join(save_dir, f\"mlp_fold_{fold}.pt\"))\n",
        "\n",
        "        # eval\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            X_va = torch.tensor(Xtr_s[va_idx], dtype=torch.float32).to(device)\n",
        "            val_p = model(X_va).detach().cpu().numpy()\n",
        "            oof_dx[va_idx], oof_dy[va_idx] = val_p[:, 0], val_p[:, 1]\n",
        "\n",
        "            X_te = torch.tensor(Xte_s, dtype=torch.float32).to(device)\n",
        "            te_p = model(X_te).detach().cpu().numpy()\n",
        "            test_dx += te_p[:, 0] / n_splits\n",
        "            test_dy += te_p[:, 1] / n_splits\n",
        "\n",
        "        print(f\"MLP Fold {fold} Done\")\n",
        "\n",
        "    return oof_dx, oof_dy, test_dx, test_dy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEUtau2Zm6uw"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_dx, y_dy, groups, test_epi, cat_features = build_dataset(df_copy)\n",
        "\n",
        "def run_catboost_pipeline(\n",
        "    X_train, y_dx, y_dy, X_test, groups, cat_features,\n",
        "    long_threshold=35.0, min_long_samples=50, verbose=200\n",
        "):\n",
        "    cb_oof_dx, cb_oof_dy, cb_test_dx, cb_test_dy, cb_fi, cb_oof_df = train_residual_pipeline_cat(\n",
        "        X_train, y_dx, y_dy, X_test, groups, cat_features,\n",
        "        long_threshold=long_threshold,\n",
        "        min_long_samples=min_long_samples,\n",
        "        verbose=verbose\n",
        "    )\n",
        "    return cb_oof_dx, cb_oof_dy, cb_test_dx, cb_test_dy, cb_oof_df, cb_fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wrd0ltm-kwuo",
        "outputId": "9d03063a-dfa3-4dd5-bc2c-4bfd8a182dab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== [CatBoost] 5-Fold Training (Base + LongSwap + Fixer) =====\n",
            "\n",
            "--- Fold 1 ---\n",
            "0:\tlearn: 16.0111154\ttest: 15.9181020\tbest: 15.9181020 (0)\ttotal: 96.5ms\tremaining: 9m 38s\n",
            "200:\tlearn: 10.9461143\ttest: 11.6283953\tbest: 11.6283953 (200)\ttotal: 20s\tremaining: 9m 35s\n",
            "400:\tlearn: 10.2273040\ttest: 11.4526273\tbest: 11.4521784 (399)\ttotal: 41.2s\tremaining: 9m 35s\n",
            "600:\tlearn: 9.5259459\ttest: 11.3788610\tbest: 11.3788610 (600)\ttotal: 1m 1s\tremaining: 9m 10s\n",
            "800:\tlearn: 8.9523175\ttest: 11.3588203\tbest: 11.3554834 (773)\ttotal: 1m 25s\tremaining: 9m 12s\n",
            "1000:\tlearn: 8.3748086\ttest: 11.3537590\tbest: 11.3503561 (914)\ttotal: 2m 5s\tremaining: 10m 29s\n",
            "Stopped by overfitting detector  (200 iterations wait)\n",
            "\n",
            "bestTest = 11.3503561\n",
            "bestIteration = 914\n",
            "\n",
            "Shrink model to first 915 iterations.\n",
            "0:\tlearn: 14.9576729\ttest: 14.7510436\tbest: 14.7510436 (0)\ttotal: 221ms\tremaining: 22m 7s\n",
            "200:\tlearn: 11.7135582\ttest: 12.4239115\tbest: 12.4239115 (200)\ttotal: 34.9s\tremaining: 16m 47s\n",
            "400:\tlearn: 10.9114416\ttest: 12.2440244\tbest: 12.2440244 (400)\ttotal: 56.5s\tremaining: 13m 8s\n",
            "600:\tlearn: 10.0073323\ttest: 12.1374910\tbest: 12.1374910 (600)\ttotal: 1m 16s\tremaining: 11m 26s\n",
            "800:\tlearn: 9.2795010\ttest: 12.1130577\tbest: 12.1123850 (798)\ttotal: 1m 38s\tremaining: 10m 41s\n",
            "1000:\tlearn: 8.6474738\ttest: 12.0972754\tbest: 12.0934616 (986)\ttotal: 2m\tremaining: 10m\n",
            "1200:\tlearn: 8.1120566\ttest: 12.0867274\tbest: 12.0858839 (1198)\ttotal: 2m 22s\tremaining: 9m 29s\n",
            "1400:\tlearn: 7.5970286\ttest: 12.0893439\tbest: 12.0847860 (1297)\ttotal: 2m 44s\tremaining: 9m\n",
            "Stopped by overfitting detector  (200 iterations wait)\n",
            "\n",
            "bestTest = 12.084786\n",
            "bestIteration = 1297\n",
            "\n",
            "Shrink model to first 1298 iterations.\n",
            "0:\tlearn: 6.5232510\ttest: 8.2667441\tbest: 8.2667441 (0)\ttotal: 43.9ms\tremaining: 43.8s\n",
            "200:\tlearn: 6.3083759\ttest: 8.1891628\tbest: 8.1890857 (196)\ttotal: 9.34s\tremaining: 37.1s\n",
            "400:\tlearn: 6.1462948\ttest: 8.1768584\tbest: 8.1760218 (396)\ttotal: 18.7s\tremaining: 27.9s\n",
            "600:\tlearn: 6.0156132\ttest: 8.1752478\tbest: 8.1747633 (592)\ttotal: 26.5s\tremaining: 17.6s\n",
            "800:\tlearn: 5.8878112\ttest: 8.1725685\tbest: 8.1701850 (689)\ttotal: 36.3s\tremaining: 9.02s\n",
            "Stopped by overfitting detector  (250 iterations wait)\n",
            "\n",
            "bestTest = 8.170184959\n",
            "bestIteration = 689\n",
            "\n",
            "Shrink model to first 690 iterations.\n",
            "0:\tlearn: 5.8675649\ttest: 8.2943501\tbest: 8.2943501 (0)\ttotal: 47ms\tremaining: 46.9s\n",
            "200:\tlearn: 5.5992912\ttest: 8.1160308\tbest: 8.1160284 (199)\ttotal: 7.8s\tremaining: 31s\n",
            "400:\tlearn: 5.4615111\ttest: 8.0942134\tbest: 8.0942134 (400)\ttotal: 17.1s\tremaining: 25.5s\n",
            "600:\tlearn: 5.3380765\ttest: 8.0853947\tbest: 8.0853947 (600)\ttotal: 25.1s\tremaining: 16.6s\n",
            "800:\tlearn: 5.2397935\ttest: 8.0791750\tbest: 8.0782149 (740)\ttotal: 34.6s\tremaining: 8.6s\n",
            "999:\tlearn: 5.1576606\ttest: 8.0758395\tbest: 8.0758150 (989)\ttotal: 44.2s\tremaining: 0us\n",
            "\n",
            "bestTest = 8.075814968\n",
            "bestIteration = 989\n",
            "\n",
            "Shrink model to first 990 iterations.\n",
            "\n",
            "--- Fold 2 ---\n",
            "0:\tlearn: 15.9424016\ttest: 16.1898066\tbest: 16.1898066 (0)\ttotal: 90.9ms\tremaining: 9m 5s\n",
            "200:\tlearn: 10.9791775\ttest: 11.7150463\tbest: 11.7150463 (200)\ttotal: 20.6s\tremaining: 9m 53s\n",
            "400:\tlearn: 10.1673490\ttest: 11.5363475\tbest: 11.5363475 (400)\ttotal: 42s\tremaining: 9m 46s\n",
            "600:\tlearn: 9.3992881\ttest: 11.4684456\tbest: 11.4684456 (600)\ttotal: 1m 2s\tremaining: 9m 20s\n",
            "800:\tlearn: 8.7417822\ttest: 11.4538904\tbest: 11.4524297 (794)\ttotal: 1m 24s\tremaining: 9m 8s\n",
            "Stopped by overfitting detector  (200 iterations wait)\n",
            "\n",
            "bestTest = 11.45242972\n",
            "bestIteration = 794\n",
            "\n",
            "Shrink model to first 795 iterations.\n",
            "0:\tlearn: 14.8897902\ttest: 15.0286467\tbest: 15.0286467 (0)\ttotal: 92.4ms\tremaining: 9m 14s\n",
            "200:\tlearn: 11.5990130\ttest: 12.7073551\tbest: 12.7073551 (200)\ttotal: 21.8s\tremaining: 10m 28s\n",
            "400:\tlearn: 10.8304832\ttest: 12.5766800\tbest: 12.5766800 (400)\ttotal: 40.6s\tremaining: 9m 26s\n",
            "600:\tlearn: 9.9119517\ttest: 12.4663997\tbest: 12.4663997 (600)\ttotal: 1m 2s\tremaining: 9m 19s\n",
            "800:\tlearn: 9.2064203\ttest: 12.4392867\tbest: 12.4387009 (762)\ttotal: 1m 22s\tremaining: 8m 56s\n",
            "1000:\tlearn: 8.6698009\ttest: 12.4279140\tbest: 12.4262968 (910)\ttotal: 1m 45s\tremaining: 8m 44s\n",
            "1200:\tlearn: 8.1530022\ttest: 12.4130916\tbest: 12.4121291 (1197)\ttotal: 2m 5s\tremaining: 8m 22s\n",
            "1400:\tlearn: 7.6711518\ttest: 12.4137172\tbest: 12.4105575 (1253)\ttotal: 2m 27s\tremaining: 8m 5s\n",
            "Stopped by overfitting detector  (200 iterations wait)\n",
            "\n",
            "bestTest = 12.41055755\n",
            "bestIteration = 1253\n",
            "\n",
            "Shrink model to first 1254 iterations.\n",
            "0:\tlearn: 6.6648611\ttest: 8.3945503\tbest: 8.3945503 (0)\ttotal: 84.5ms\tremaining: 1m 24s\n",
            "200:\tlearn: 6.4412255\ttest: 8.3091267\tbest: 8.3091267 (200)\ttotal: 8.52s\tremaining: 33.9s\n",
            "400:\tlearn: 6.2734118\ttest: 8.2875413\tbest: 8.2874583 (399)\ttotal: 18s\tremaining: 26.9s\n",
            "600:\tlearn: 6.1090366\ttest: 8.2835774\tbest: 8.2809566 (490)\ttotal: 26s\tremaining: 17.2s\n",
            "800:\tlearn: 5.9884357\ttest: 8.2815134\tbest: 8.2801188 (760)\ttotal: 35.5s\tremaining: 8.82s\n",
            "999:\tlearn: 5.8738099\ttest: 8.2803669\tbest: 8.2787668 (904)\ttotal: 45.1s\tremaining: 0us\n",
            "\n",
            "bestTest = 8.278766787\n",
            "bestIteration = 904\n",
            "\n",
            "Shrink model to first 905 iterations.\n",
            "0:\tlearn: 5.9108960\ttest: 8.6071851\tbest: 8.6071851 (0)\ttotal: 41.9ms\tremaining: 41.8s\n",
            "200:\tlearn: 5.6288912\ttest: 8.4392826\tbest: 8.4392826 (200)\ttotal: 7.4s\tremaining: 29.4s\n",
            "400:\tlearn: 5.5029335\ttest: 8.4248041\tbest: 8.4240265 (379)\ttotal: 16.9s\tremaining: 25.2s\n",
            "600:\tlearn: 5.3742141\ttest: 8.4155616\tbest: 8.4155592 (599)\ttotal: 26.5s\tremaining: 17.6s\n",
            "800:\tlearn: 5.2761210\ttest: 8.4094907\tbest: 8.4081793 (759)\ttotal: 34.4s\tremaining: 8.55s\n",
            "999:\tlearn: 5.2052552\ttest: 8.4049794\tbest: 8.4048578 (991)\ttotal: 44s\tremaining: 0us\n",
            "\n",
            "bestTest = 8.404857773\n",
            "bestIteration = 991\n",
            "\n",
            "Shrink model to first 992 iterations.\n",
            "\n",
            "--- Fold 3 ---\n",
            "0:\tlearn: 16.0460939\ttest: 15.7802127\tbest: 15.7802127 (0)\ttotal: 92.6ms\tremaining: 9m 15s\n",
            "200:\tlearn: 10.9523503\ttest: 11.7128411\tbest: 11.7124213 (199)\ttotal: 21.1s\tremaining: 10m 9s\n",
            "400:\tlearn: 10.1788994\ttest: 11.6060073\tbest: 11.6042285 (396)\ttotal: 41.6s\tremaining: 9m 40s\n",
            "600:\tlearn: 9.4282013\ttest: 11.5745246\tbest: 11.5717008 (573)\ttotal: 1m 2s\tremaining: 9m 25s\n",
            "800:\tlearn: 8.8103184\ttest: 11.5592410\tbest: 11.5552581 (729)\ttotal: 1m 24s\tremaining: 9m 7s\n",
            "Stopped by overfitting detector  (200 iterations wait)\n",
            "\n",
            "bestTest = 11.55525809\n",
            "bestIteration = 729\n",
            "\n",
            "Shrink model to first 730 iterations.\n",
            "0:\tlearn: 14.8733322\ttest: 15.0719943\tbest: 15.0719943 (0)\ttotal: 93ms\tremaining: 9m 17s\n",
            "200:\tlearn: 11.6791343\ttest: 12.7257944\tbest: 12.7257944 (200)\ttotal: 20.7s\tremaining: 9m 57s\n",
            "400:\tlearn: 10.8549696\ttest: 12.5336487\tbest: 12.5336487 (400)\ttotal: 40.9s\tremaining: 9m 30s\n",
            "600:\tlearn: 9.9902868\ttest: 12.4400264\tbest: 12.4396856 (597)\ttotal: 1m 2s\tremaining: 9m 18s\n",
            "800:\tlearn: 9.2374274\ttest: 12.3948982\tbest: 12.3945449 (796)\ttotal: 1m 23s\tremaining: 8m 59s\n",
            "1000:\tlearn: 8.6020384\ttest: 12.3787126\tbest: 12.3787126 (1000)\ttotal: 1m 44s\tremaining: 8m 42s\n",
            "1200:\tlearn: 8.0348502\ttest: 12.3612968\tbest: 12.3597846 (1199)\ttotal: 2m 5s\tremaining: 8m 20s\n",
            "1400:\tlearn: 7.5131509\ttest: 12.3576224\tbest: 12.3533471 (1327)\ttotal: 2m 27s\tremaining: 8m 4s\n",
            "1600:\tlearn: 7.0566712\ttest: 12.3525879\tbest: 12.3506387 (1468)\ttotal: 2m 48s\tremaining: 7m 41s\n",
            "Stopped by overfitting detector  (200 iterations wait)\n",
            "\n",
            "bestTest = 12.35063869\n",
            "bestIteration = 1468\n",
            "\n",
            "Shrink model to first 1469 iterations.\n",
            "0:\tlearn: 6.8193709\ttest: 8.4642204\tbest: 8.4642204 (0)\ttotal: 39ms\tremaining: 38.9s\n",
            "200:\tlearn: 6.5830888\ttest: 8.3436005\tbest: 8.3430858 (198)\ttotal: 7s\tremaining: 27.8s\n",
            "400:\tlearn: 6.4139340\ttest: 8.3336817\tbest: 8.3333667 (383)\ttotal: 16.6s\tremaining: 24.8s\n",
            "600:\tlearn: 6.2322426\ttest: 8.3303617\tbest: 8.3289087 (574)\ttotal: 26.2s\tremaining: 17.4s\n",
            "800:\tlearn: 6.0997120\ttest: 8.3327636\tbest: 8.3277725 (639)\ttotal: 34.1s\tremaining: 8.48s\n",
            "Stopped by overfitting detector  (250 iterations wait)\n",
            "\n",
            "bestTest = 8.327772487\n",
            "bestIteration = 639\n",
            "\n",
            "Shrink model to first 640 iterations.\n",
            "0:\tlearn: 5.4459596\ttest: 8.4344421\tbest: 8.4344421 (0)\ttotal: 40.4ms\tremaining: 40.4s\n",
            "200:\tlearn: 5.2117111\ttest: 8.3134463\tbest: 8.3134463 (200)\ttotal: 7.3s\tremaining: 29s\n",
            "400:\tlearn: 5.1137643\ttest: 8.2993228\tbest: 8.2992560 (394)\ttotal: 16.6s\tremaining: 24.8s\n",
            "600:\tlearn: 5.0097740\ttest: 8.2887123\tbest: 8.2883933 (580)\ttotal: 26.2s\tremaining: 17.4s\n",
            "800:\tlearn: 4.9188297\ttest: 8.2824886\tbest: 8.2823700 (788)\ttotal: 34s\tremaining: 8.46s\n",
            "999:\tlearn: 4.8425300\ttest: 8.2776585\tbest: 8.2773206 (990)\ttotal: 43.7s\tremaining: 0us\n",
            "\n",
            "bestTest = 8.277320608\n",
            "bestIteration = 990\n",
            "\n",
            "Shrink model to first 991 iterations.\n",
            "\n",
            "--- Fold 4 ---\n",
            "0:\tlearn: 15.9915117\ttest: 15.9994065\tbest: 15.9994065 (0)\ttotal: 91.3ms\tremaining: 9m 7s\n",
            "200:\tlearn: 10.9035418\ttest: 11.5064800\tbest: 11.5058842 (199)\ttotal: 19.2s\tremaining: 9m 13s\n",
            "400:\tlearn: 10.1169290\ttest: 11.3858553\tbest: 11.3854814 (399)\ttotal: 39.9s\tremaining: 9m 17s\n",
            "600:\tlearn: 9.3896614\ttest: 11.3502296\tbest: 11.3481523 (590)\ttotal: 59.2s\tremaining: 8m 51s\n",
            "800:\tlearn: 8.7681805\ttest: 11.3407524\tbest: 11.3395108 (734)\ttotal: 1m 20s\tremaining: 8m 42s\n",
            "Stopped by overfitting detector  (200 iterations wait)\n",
            "\n",
            "bestTest = 11.3395108\n",
            "bestIteration = 734\n",
            "\n",
            "Shrink model to first 735 iterations.\n",
            "0:\tlearn: 14.9726794\ttest: 14.7432938\tbest: 14.7432938 (0)\ttotal: 88.8ms\tremaining: 8m 52s\n",
            "200:\tlearn: 11.6471216\ttest: 12.2614809\tbest: 12.2614809 (200)\ttotal: 19.1s\tremaining: 9m 10s\n",
            "400:\tlearn: 10.9386228\ttest: 12.1071157\tbest: 12.1071157 (400)\ttotal: 38.2s\tremaining: 8m 53s\n",
            "600:\tlearn: 10.2279919\ttest: 12.0178114\tbest: 12.0178114 (600)\ttotal: 57.7s\tremaining: 8m 38s\n",
            "800:\tlearn: 9.4853747\ttest: 11.9818688\tbest: 11.9818688 (800)\ttotal: 1m 17s\tremaining: 8m 20s\n",
            "1000:\tlearn: 8.7914386\ttest: 11.9580980\tbest: 11.9577759 (986)\ttotal: 1m 38s\tremaining: 8m 10s\n",
            "1200:\tlearn: 8.2625921\ttest: 11.9527920\tbest: 11.9461148 (1119)\ttotal: 1m 57s\tremaining: 7m 49s\n",
            "Stopped by overfitting detector  (200 iterations wait)\n",
            "\n",
            "bestTest = 11.94611484\n",
            "bestIteration = 1119\n",
            "\n",
            "Shrink model to first 1120 iterations.\n",
            "0:\tlearn: 6.7993343\ttest: 8.3842532\tbest: 8.3842532 (0)\ttotal: 39.5ms\tremaining: 39.5s\n",
            "200:\tlearn: 6.5312309\ttest: 8.2650648\tbest: 8.2650648 (200)\ttotal: 8.74s\tremaining: 34.7s\n",
            "400:\tlearn: 6.3527791\ttest: 8.2478234\tbest: 8.2477901 (399)\ttotal: 15.9s\tremaining: 23.7s\n",
            "600:\tlearn: 6.1725980\ttest: 8.2460915\tbest: 8.2442690 (508)\ttotal: 24.9s\tremaining: 16.5s\n",
            "800:\tlearn: 6.0206806\ttest: 8.2369386\tbest: 8.2369386 (800)\ttotal: 33.9s\tremaining: 8.43s\n",
            "999:\tlearn: 5.8896135\ttest: 8.2370561\tbest: 8.2357614 (898)\ttotal: 41.3s\tremaining: 0us\n",
            "\n",
            "bestTest = 8.235761414\n",
            "bestIteration = 898\n",
            "\n",
            "Shrink model to first 899 iterations.\n",
            "0:\tlearn: 6.1717227\ttest: 8.3861903\tbest: 8.3861903 (0)\ttotal: 41ms\tremaining: 40.9s\n",
            "200:\tlearn: 5.8786052\ttest: 8.1693309\tbest: 8.1693055 (199)\ttotal: 8.63s\tremaining: 34.3s\n",
            "400:\tlearn: 5.7282224\ttest: 8.1381864\tbest: 8.1381864 (400)\ttotal: 15.6s\tremaining: 23.3s\n",
            "600:\tlearn: 5.6074070\ttest: 8.1195414\tbest: 8.1195396 (598)\ttotal: 24.6s\tremaining: 16.3s\n",
            "800:\tlearn: 5.5088572\ttest: 8.1111801\tbest: 8.1111271 (796)\ttotal: 33.7s\tremaining: 8.36s\n",
            "999:\tlearn: 5.4272906\ttest: 8.1034999\tbest: 8.1033843 (987)\ttotal: 40.8s\tremaining: 0us\n",
            "\n",
            "bestTest = 8.10338432\n",
            "bestIteration = 987\n",
            "\n",
            "Shrink model to first 988 iterations.\n",
            "\n",
            "--- Fold 5 ---\n",
            "0:\tlearn: 15.9715233\ttest: 16.0951775\tbest: 16.0951775 (0)\ttotal: 89.4ms\tremaining: 8m 56s\n",
            "200:\tlearn: 10.9782441\ttest: 11.5571543\tbest: 11.5571543 (200)\ttotal: 22.1s\tremaining: 10m 37s\n",
            "400:\tlearn: 10.2154115\ttest: 11.3806079\tbest: 11.3806079 (400)\ttotal: 42.1s\tremaining: 9m 47s\n",
            "600:\tlearn: 9.4905500\ttest: 11.3093649\tbest: 11.3071412 (590)\ttotal: 1m 4s\tremaining: 9m 36s\n",
            "800:\tlearn: 8.8827726\ttest: 11.2915840\tbest: 11.2907608 (794)\ttotal: 1m 24s\tremaining: 9m 9s\n",
            "1000:\tlearn: 8.2929370\ttest: 11.2774072\tbest: 11.2758825 (914)\ttotal: 1m 46s\tremaining: 8m 53s\n",
            "Stopped by overfitting detector  (200 iterations wait)\n",
            "\n",
            "bestTest = 11.27588254\n",
            "bestIteration = 914\n",
            "\n",
            "Shrink model to first 915 iterations.\n",
            "0:\tlearn: 14.9008397\ttest: 15.0267905\tbest: 15.0267905 (0)\ttotal: 89ms\tremaining: 8m 53s\n",
            "200:\tlearn: 11.6249259\ttest: 12.7381006\tbest: 12.7381006 (200)\ttotal: 19.5s\tremaining: 9m 22s\n",
            "400:\tlearn: 10.8794217\ttest: 12.5704772\tbest: 12.5704772 (400)\ttotal: 40.3s\tremaining: 9m 23s\n",
            "600:\tlearn: 10.0359186\ttest: 12.4807978\tbest: 12.4805352 (596)\ttotal: 1m\tremaining: 9m 1s\n",
            "800:\tlearn: 9.3548888\ttest: 12.4229599\tbest: 12.4221873 (790)\ttotal: 1m 22s\tremaining: 8m 52s\n",
            "1000:\tlearn: 8.7210632\ttest: 12.3929683\tbest: 12.3929683 (1000)\ttotal: 1m 42s\tremaining: 8m 30s\n",
            "1200:\tlearn: 8.1260347\ttest: 12.3811275\tbest: 12.3791777 (1169)\ttotal: 2m 4s\tremaining: 8m 15s\n",
            "1400:\tlearn: 7.6019649\ttest: 12.3767432\tbest: 12.3745868 (1241)\ttotal: 2m 24s\tremaining: 7m 53s\n",
            "Stopped by overfitting detector  (200 iterations wait)\n",
            "\n",
            "bestTest = 12.37458678\n",
            "bestIteration = 1241\n",
            "\n",
            "Shrink model to first 1242 iterations.\n",
            "0:\tlearn: 6.5631155\ttest: 8.1280792\tbest: 8.1280792 (0)\ttotal: 48.6ms\tremaining: 48.6s\n",
            "200:\tlearn: 6.3353282\ttest: 8.0682773\tbest: 8.0680360 (194)\ttotal: 7.32s\tremaining: 29.1s\n",
            "400:\tlearn: 6.1718540\ttest: 8.0564960\tbest: 8.0560962 (395)\ttotal: 16.7s\tremaining: 25s\n",
            "600:\tlearn: 6.0174555\ttest: 8.0585526\tbest: 8.0535663 (430)\ttotal: 25.4s\tremaining: 16.9s\n",
            "Stopped by overfitting detector  (250 iterations wait)\n",
            "\n",
            "bestTest = 8.053566328\n",
            "bestIteration = 430\n",
            "\n",
            "Shrink model to first 431 iterations.\n",
            "0:\tlearn: 5.8975678\ttest: 8.4923958\tbest: 8.4923958 (0)\ttotal: 40.8ms\tremaining: 40.8s\n",
            "200:\tlearn: 5.6436164\ttest: 8.3544619\tbest: 8.3544619 (200)\ttotal: 7.42s\tremaining: 29.5s\n",
            "400:\tlearn: 5.5130667\ttest: 8.3345692\tbest: 8.3345692 (400)\ttotal: 16.8s\tremaining: 25.1s\n",
            "600:\tlearn: 5.3810120\ttest: 8.3172891\tbest: 8.3172891 (600)\ttotal: 26.5s\tremaining: 17.6s\n",
            "800:\tlearn: 5.2774880\ttest: 8.3158582\tbest: 8.3139770 (717)\ttotal: 34.4s\tremaining: 8.54s\n",
            "999:\tlearn: 5.1878313\ttest: 8.3141645\tbest: 8.3122217 (910)\ttotal: 44s\tremaining: 0us\n",
            "\n",
            "bestTest = 8.312221693\n",
            "bestIteration = 910\n",
            "\n",
            "Shrink model to first 911 iterations.\n",
            "\n",
            "[CatBoost] OOF: 13.0940m\n"
          ]
        }
      ],
      "source": [
        "# --- CatBoost ---\n",
        "cb_oof_dx, cb_oof_dy, cb_test_dx, cb_test_dy, cb_oof_df, cb_fi = run_catboost_pipeline(\n",
        "    X_train, y_dx, y_dy, X_test, groups, cat_features,\n",
        "    long_threshold=35.0, min_long_samples=50, verbose=200\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b80d3bd8-9b72-470c-d92d-4151a76227db",
        "id": "-B_UPQwc5wiP"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== [LightGBM] 5-Fold Training (Base + Fixer + LongSwap) =====\n",
            "\n",
            "[LGBM] Fold 1\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 14.6073\n",
            "[400]\tvalid_0's rmse: 13.6277\n",
            "[600]\tvalid_0's rmse: 12.9871\n",
            "[800]\tvalid_0's rmse: 12.5689\n",
            "[1000]\tvalid_0's rmse: 12.2885\n",
            "[1200]\tvalid_0's rmse: 12.0957\n",
            "[1400]\tvalid_0's rmse: 11.9552\n",
            "[1600]\tvalid_0's rmse: 11.8516\n",
            "[1800]\tvalid_0's rmse: 11.7766\n",
            "[2000]\tvalid_0's rmse: 11.7279\n",
            "[2200]\tvalid_0's rmse: 11.6963\n",
            "[2400]\tvalid_0's rmse: 11.6764\n",
            "[2600]\tvalid_0's rmse: 11.6608\n",
            "[2800]\tvalid_0's rmse: 11.6502\n",
            "[3000]\tvalid_0's rmse: 11.6424\n",
            "[3200]\tvalid_0's rmse: 11.6346\n",
            "[3400]\tvalid_0's rmse: 11.6293\n",
            "[3600]\tvalid_0's rmse: 11.6228\n",
            "[3800]\tvalid_0's rmse: 11.6187\n",
            "[4000]\tvalid_0's rmse: 11.6156\n",
            "[4200]\tvalid_0's rmse: 11.6126\n",
            "[4400]\tvalid_0's rmse: 11.6087\n",
            "[4600]\tvalid_0's rmse: 11.6068\n",
            "[4800]\tvalid_0's rmse: 11.6025\n",
            "[5000]\tvalid_0's rmse: 11.6003\n",
            "[5200]\tvalid_0's rmse: 11.6001\n",
            "Early stopping, best iteration is:\n",
            "[5073]\tvalid_0's rmse: 11.5991\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 13.9599\n",
            "[400]\tvalid_0's rmse: 13.4583\n",
            "[600]\tvalid_0's rmse: 13.1427\n",
            "[800]\tvalid_0's rmse: 12.9339\n",
            "[1000]\tvalid_0's rmse: 12.8014\n",
            "[1200]\tvalid_0's rmse: 12.7175\n",
            "[1400]\tvalid_0's rmse: 12.6616\n",
            "[1600]\tvalid_0's rmse: 12.6174\n",
            "[1800]\tvalid_0's rmse: 12.579\n",
            "[2000]\tvalid_0's rmse: 12.5541\n",
            "[2200]\tvalid_0's rmse: 12.5316\n",
            "[2400]\tvalid_0's rmse: 12.5143\n",
            "[2600]\tvalid_0's rmse: 12.5003\n",
            "[2800]\tvalid_0's rmse: 12.4866\n",
            "[3000]\tvalid_0's rmse: 12.472\n",
            "[3200]\tvalid_0's rmse: 12.4631\n",
            "[3400]\tvalid_0's rmse: 12.4538\n",
            "[3600]\tvalid_0's rmse: 12.444\n",
            "[3800]\tvalid_0's rmse: 12.437\n",
            "[4000]\tvalid_0's rmse: 12.4272\n",
            "[4200]\tvalid_0's rmse: 12.4199\n",
            "[4400]\tvalid_0's rmse: 12.4117\n",
            "[4600]\tvalid_0's rmse: 12.4059\n",
            "[4800]\tvalid_0's rmse: 12.4018\n",
            "[5000]\tvalid_0's rmse: 12.3989\n",
            "[5200]\tvalid_0's rmse: 12.3939\n",
            "[5400]\tvalid_0's rmse: 12.3894\n",
            "[5600]\tvalid_0's rmse: 12.3859\n",
            "[5800]\tvalid_0's rmse: 12.3829\n",
            "[6000]\tvalid_0's rmse: 12.379\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[6000]\tvalid_0's rmse: 12.379\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 11.6006\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's rmse: 11.599\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 12.3757\n",
            "[400]\tvalid_0's rmse: 12.3727\n",
            "[600]\tvalid_0's rmse: 12.367\n",
            "[800]\tvalid_0's rmse: 12.3664\n",
            "[1000]\tvalid_0's rmse: 12.3657\n",
            "[1200]\tvalid_0's rmse: 12.3623\n",
            "[1400]\tvalid_0's rmse: 12.3609\n",
            "[1600]\tvalid_0's rmse: 12.3595\n",
            "[1800]\tvalid_0's rmse: 12.3577\n",
            "[2000]\tvalid_0's rmse: 12.3576\n",
            "[2200]\tvalid_0's rmse: 12.3579\n",
            "[2400]\tvalid_0's rmse: 12.3563\n",
            "[2600]\tvalid_0's rmse: 12.3555\n",
            "[2800]\tvalid_0's rmse: 12.355\n",
            "[3000]\tvalid_0's rmse: 12.3542\n",
            "[3200]\tvalid_0's rmse: 12.352\n",
            "[3400]\tvalid_0's rmse: 12.3526\n",
            "Early stopping, best iteration is:\n",
            "[3264]\tvalid_0's rmse: 12.3515\n",
            "\n",
            "[LGBM] Fold 2\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 14.8429\n",
            "[400]\tvalid_0's rmse: 13.8201\n",
            "[600]\tvalid_0's rmse: 13.1426\n",
            "[800]\tvalid_0's rmse: 12.688\n",
            "[1000]\tvalid_0's rmse: 12.3771\n",
            "[1200]\tvalid_0's rmse: 12.1577\n",
            "[1400]\tvalid_0's rmse: 12.0036\n",
            "[1600]\tvalid_0's rmse: 11.8954\n",
            "[1800]\tvalid_0's rmse: 11.8167\n",
            "[2000]\tvalid_0's rmse: 11.7607\n",
            "[2200]\tvalid_0's rmse: 11.7213\n",
            "[2400]\tvalid_0's rmse: 11.6917\n",
            "[2600]\tvalid_0's rmse: 11.671\n",
            "[2800]\tvalid_0's rmse: 11.658\n",
            "[3000]\tvalid_0's rmse: 11.648\n",
            "[3200]\tvalid_0's rmse: 11.6405\n",
            "[3400]\tvalid_0's rmse: 11.6348\n",
            "[3600]\tvalid_0's rmse: 11.6297\n",
            "[3800]\tvalid_0's rmse: 11.6255\n",
            "[4000]\tvalid_0's rmse: 11.6233\n",
            "[4200]\tvalid_0's rmse: 11.6196\n",
            "[4400]\tvalid_0's rmse: 11.6184\n",
            "[4600]\tvalid_0's rmse: 11.6165\n",
            "[4800]\tvalid_0's rmse: 11.6161\n",
            "[5000]\tvalid_0's rmse: 11.6143\n",
            "Early stopping, best iteration is:\n",
            "[4956]\tvalid_0's rmse: 11.6138\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 14.2056\n",
            "[400]\tvalid_0's rmse: 13.6893\n",
            "[600]\tvalid_0's rmse: 13.3637\n",
            "[800]\tvalid_0's rmse: 13.1569\n",
            "[1000]\tvalid_0's rmse: 13.0288\n",
            "[1200]\tvalid_0's rmse: 12.9496\n",
            "[1400]\tvalid_0's rmse: 12.9054\n",
            "[1600]\tvalid_0's rmse: 12.8781\n",
            "[1800]\tvalid_0's rmse: 12.8573\n",
            "[2000]\tvalid_0's rmse: 12.8448\n",
            "[2200]\tvalid_0's rmse: 12.8343\n",
            "[2400]\tvalid_0's rmse: 12.8266\n",
            "[2600]\tvalid_0's rmse: 12.8204\n",
            "[2800]\tvalid_0's rmse: 12.8168\n",
            "[3000]\tvalid_0's rmse: 12.8123\n",
            "[3200]\tvalid_0's rmse: 12.807\n",
            "[3400]\tvalid_0's rmse: 12.8036\n",
            "[3600]\tvalid_0's rmse: 12.801\n",
            "[3800]\tvalid_0's rmse: 12.7976\n",
            "[4000]\tvalid_0's rmse: 12.7936\n",
            "[4200]\tvalid_0's rmse: 12.7915\n",
            "[4400]\tvalid_0's rmse: 12.7884\n",
            "[4600]\tvalid_0's rmse: 12.7873\n",
            "[4800]\tvalid_0's rmse: 12.7819\n",
            "[5000]\tvalid_0's rmse: 12.779\n",
            "[5200]\tvalid_0's rmse: 12.7763\n",
            "[5400]\tvalid_0's rmse: 12.7751\n",
            "[5600]\tvalid_0's rmse: 12.7718\n",
            "[5800]\tvalid_0's rmse: 12.7675\n",
            "[6000]\tvalid_0's rmse: 12.7655\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5962]\tvalid_0's rmse: 12.7654\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 11.6123\n",
            "[400]\tvalid_0's rmse: 11.6085\n",
            "[600]\tvalid_0's rmse: 11.6096\n",
            "Early stopping, best iteration is:\n",
            "[436]\tvalid_0's rmse: 11.6066\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 12.7683\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's rmse: 12.7644\n",
            "\n",
            "[LGBM] Fold 3\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 14.4118\n",
            "[400]\tvalid_0's rmse: 13.3951\n",
            "[600]\tvalid_0's rmse: 12.7366\n",
            "[800]\tvalid_0's rmse: 12.3194\n",
            "[1000]\tvalid_0's rmse: 12.053\n",
            "[1200]\tvalid_0's rmse: 11.8763\n",
            "[1400]\tvalid_0's rmse: 11.7617\n",
            "[1600]\tvalid_0's rmse: 11.6907\n",
            "[1800]\tvalid_0's rmse: 11.6468\n",
            "[2000]\tvalid_0's rmse: 11.6194\n",
            "[2200]\tvalid_0's rmse: 11.6005\n",
            "[2400]\tvalid_0's rmse: 11.5879\n",
            "[2600]\tvalid_0's rmse: 11.5806\n",
            "[2800]\tvalid_0's rmse: 11.5784\n",
            "[3000]\tvalid_0's rmse: 11.5779\n",
            "Early stopping, best iteration is:\n",
            "[2844]\tvalid_0's rmse: 11.5768\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 14.3258\n",
            "[400]\tvalid_0's rmse: 13.8433\n",
            "[600]\tvalid_0's rmse: 13.5251\n",
            "[800]\tvalid_0's rmse: 13.3213\n",
            "[1000]\tvalid_0's rmse: 13.1856\n",
            "[1200]\tvalid_0's rmse: 13.0966\n",
            "[1400]\tvalid_0's rmse: 13.0318\n",
            "[1600]\tvalid_0's rmse: 12.9842\n",
            "[1800]\tvalid_0's rmse: 12.9476\n",
            "[2000]\tvalid_0's rmse: 12.9171\n",
            "[2200]\tvalid_0's rmse: 12.8921\n",
            "[2400]\tvalid_0's rmse: 12.8679\n",
            "[2600]\tvalid_0's rmse: 12.8521\n",
            "[2800]\tvalid_0's rmse: 12.8329\n",
            "[3000]\tvalid_0's rmse: 12.8179\n",
            "[3200]\tvalid_0's rmse: 12.8023\n",
            "[3400]\tvalid_0's rmse: 12.7874\n",
            "[3600]\tvalid_0's rmse: 12.7748\n",
            "[3800]\tvalid_0's rmse: 12.7626\n",
            "[4000]\tvalid_0's rmse: 12.7511\n",
            "[4200]\tvalid_0's rmse: 12.7409\n",
            "[4400]\tvalid_0's rmse: 12.7305\n",
            "[4600]\tvalid_0's rmse: 12.7227\n",
            "[4800]\tvalid_0's rmse: 12.716\n",
            "[5000]\tvalid_0's rmse: 12.7059\n",
            "[5200]\tvalid_0's rmse: 12.6981\n",
            "[5400]\tvalid_0's rmse: 12.6904\n",
            "[5600]\tvalid_0's rmse: 12.6816\n",
            "[5800]\tvalid_0's rmse: 12.6754\n",
            "[6000]\tvalid_0's rmse: 12.6683\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[6000]\tvalid_0's rmse: 12.6683\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 11.5804\n",
            "Early stopping, best iteration is:\n",
            "[66]\tvalid_0's rmse: 11.5742\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 12.6656\n",
            "[400]\tvalid_0's rmse: 12.6632\n",
            "[600]\tvalid_0's rmse: 12.6602\n",
            "[800]\tvalid_0's rmse: 12.6587\n",
            "[1000]\tvalid_0's rmse: 12.6558\n",
            "[1200]\tvalid_0's rmse: 12.6505\n",
            "[1400]\tvalid_0's rmse: 12.6475\n",
            "[1600]\tvalid_0's rmse: 12.6435\n",
            "[1800]\tvalid_0's rmse: 12.6376\n",
            "[2000]\tvalid_0's rmse: 12.6351\n",
            "[2200]\tvalid_0's rmse: 12.6317\n",
            "[2400]\tvalid_0's rmse: 12.6303\n",
            "[2600]\tvalid_0's rmse: 12.6298\n",
            "[2800]\tvalid_0's rmse: 12.6291\n",
            "[3000]\tvalid_0's rmse: 12.6259\n",
            "[3200]\tvalid_0's rmse: 12.6231\n",
            "[3400]\tvalid_0's rmse: 12.6224\n",
            "[3600]\tvalid_0's rmse: 12.6191\n",
            "[3800]\tvalid_0's rmse: 12.6182\n",
            "[4000]\tvalid_0's rmse: 12.6166\n",
            "[4200]\tvalid_0's rmse: 12.6153\n",
            "[4400]\tvalid_0's rmse: 12.6148\n",
            "Early stopping, best iteration is:\n",
            "[4330]\tvalid_0's rmse: 12.6142\n",
            "\n",
            "[LGBM] Fold 4\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 14.598\n",
            "[400]\tvalid_0's rmse: 13.5183\n",
            "[600]\tvalid_0's rmse: 12.8055\n",
            "[800]\tvalid_0's rmse: 12.3265\n",
            "[1000]\tvalid_0's rmse: 12.004\n",
            "[1200]\tvalid_0's rmse: 11.7757\n",
            "[1400]\tvalid_0's rmse: 11.6142\n",
            "[1600]\tvalid_0's rmse: 11.5048\n",
            "[1800]\tvalid_0's rmse: 11.4334\n",
            "[2000]\tvalid_0's rmse: 11.3848\n",
            "[2200]\tvalid_0's rmse: 11.352\n",
            "[2400]\tvalid_0's rmse: 11.3329\n",
            "[2600]\tvalid_0's rmse: 11.3213\n",
            "[2800]\tvalid_0's rmse: 11.315\n",
            "[3000]\tvalid_0's rmse: 11.3106\n",
            "[3200]\tvalid_0's rmse: 11.3086\n",
            "[3400]\tvalid_0's rmse: 11.3067\n",
            "[3600]\tvalid_0's rmse: 11.3067\n",
            "Early stopping, best iteration is:\n",
            "[3444]\tvalid_0's rmse: 11.3056\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 13.9298\n",
            "[400]\tvalid_0's rmse: 13.3956\n",
            "[600]\tvalid_0's rmse: 13.0421\n",
            "[800]\tvalid_0's rmse: 12.8052\n",
            "[1000]\tvalid_0's rmse: 12.648\n",
            "[1200]\tvalid_0's rmse: 12.5395\n",
            "[1400]\tvalid_0's rmse: 12.4623\n",
            "[1600]\tvalid_0's rmse: 12.4017\n",
            "[1800]\tvalid_0's rmse: 12.3539\n",
            "[2000]\tvalid_0's rmse: 12.3149\n",
            "[2200]\tvalid_0's rmse: 12.2844\n",
            "[2400]\tvalid_0's rmse: 12.2601\n",
            "[2600]\tvalid_0's rmse: 12.2406\n",
            "[2800]\tvalid_0's rmse: 12.2254\n",
            "[3000]\tvalid_0's rmse: 12.2125\n",
            "[3200]\tvalid_0's rmse: 12.2021\n",
            "[3400]\tvalid_0's rmse: 12.1917\n",
            "[3600]\tvalid_0's rmse: 12.1814\n",
            "[3800]\tvalid_0's rmse: 12.1735\n",
            "[4000]\tvalid_0's rmse: 12.1673\n",
            "[4200]\tvalid_0's rmse: 12.1603\n",
            "[4400]\tvalid_0's rmse: 12.1561\n",
            "[4600]\tvalid_0's rmse: 12.1532\n",
            "[4800]\tvalid_0's rmse: 12.1486\n",
            "[5000]\tvalid_0's rmse: 12.1451\n",
            "[5200]\tvalid_0's rmse: 12.1413\n",
            "[5400]\tvalid_0's rmse: 12.1356\n",
            "[5600]\tvalid_0's rmse: 12.1316\n",
            "[5800]\tvalid_0's rmse: 12.1274\n",
            "[6000]\tvalid_0's rmse: 12.1243\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5997]\tvalid_0's rmse: 12.1241\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 11.3097\n",
            "Early stopping, best iteration is:\n",
            "[45]\tvalid_0's rmse: 11.3015\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 12.1265\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's rmse: 12.1243\n",
            "\n",
            "[LGBM] Fold 5\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 14.7221\n",
            "[400]\tvalid_0's rmse: 13.6791\n",
            "[600]\tvalid_0's rmse: 12.9836\n",
            "[800]\tvalid_0's rmse: 12.5297\n",
            "[1000]\tvalid_0's rmse: 12.2311\n",
            "[1200]\tvalid_0's rmse: 12.0198\n",
            "[1400]\tvalid_0's rmse: 11.8774\n",
            "[1600]\tvalid_0's rmse: 11.7786\n",
            "[1800]\tvalid_0's rmse: 11.7103\n",
            "[2000]\tvalid_0's rmse: 11.6695\n",
            "[2200]\tvalid_0's rmse: 11.6451\n",
            "[2400]\tvalid_0's rmse: 11.6289\n",
            "[2600]\tvalid_0's rmse: 11.6145\n",
            "[2800]\tvalid_0's rmse: 11.6041\n",
            "[3000]\tvalid_0's rmse: 11.5954\n",
            "[3200]\tvalid_0's rmse: 11.5901\n",
            "[3400]\tvalid_0's rmse: 11.5815\n",
            "[3600]\tvalid_0's rmse: 11.5771\n",
            "[3800]\tvalid_0's rmse: 11.5711\n",
            "[4000]\tvalid_0's rmse: 11.5692\n",
            "[4200]\tvalid_0's rmse: 11.5675\n",
            "Early stopping, best iteration is:\n",
            "[4112]\tvalid_0's rmse: 11.5667\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 14.3001\n",
            "[400]\tvalid_0's rmse: 13.8545\n",
            "[600]\tvalid_0's rmse: 13.5786\n",
            "[800]\tvalid_0's rmse: 13.3982\n",
            "[1000]\tvalid_0's rmse: 13.2732\n",
            "[1200]\tvalid_0's rmse: 13.1937\n",
            "[1400]\tvalid_0's rmse: 13.1395\n",
            "[1600]\tvalid_0's rmse: 13.0966\n",
            "[1800]\tvalid_0's rmse: 13.0599\n",
            "[2000]\tvalid_0's rmse: 13.0275\n",
            "[2200]\tvalid_0's rmse: 13.0019\n",
            "[2400]\tvalid_0's rmse: 12.9786\n",
            "[2600]\tvalid_0's rmse: 12.9589\n",
            "[2800]\tvalid_0's rmse: 12.9407\n",
            "[3000]\tvalid_0's rmse: 12.9238\n",
            "[3200]\tvalid_0's rmse: 12.9071\n",
            "[3400]\tvalid_0's rmse: 12.8929\n",
            "[3600]\tvalid_0's rmse: 12.8811\n",
            "[3800]\tvalid_0's rmse: 12.8716\n",
            "[4000]\tvalid_0's rmse: 12.8604\n",
            "[4200]\tvalid_0's rmse: 12.8487\n",
            "[4400]\tvalid_0's rmse: 12.8382\n",
            "[4600]\tvalid_0's rmse: 12.8307\n",
            "[4800]\tvalid_0's rmse: 12.8212\n",
            "[5000]\tvalid_0's rmse: 12.8141\n",
            "[5200]\tvalid_0's rmse: 12.8049\n",
            "[5400]\tvalid_0's rmse: 12.7976\n",
            "[5600]\tvalid_0's rmse: 12.7922\n",
            "[5800]\tvalid_0's rmse: 12.7863\n",
            "[6000]\tvalid_0's rmse: 12.7812\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5991]\tvalid_0's rmse: 12.781\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 11.5643\n",
            "[400]\tvalid_0's rmse: 11.5612\n",
            "[600]\tvalid_0's rmse: 11.5542\n",
            "[800]\tvalid_0's rmse: 11.5543\n",
            "[1000]\tvalid_0's rmse: 11.5519\n",
            "[1200]\tvalid_0's rmse: 11.5462\n",
            "[1400]\tvalid_0's rmse: 11.5419\n",
            "[1600]\tvalid_0's rmse: 11.5443\n",
            "Early stopping, best iteration is:\n",
            "[1402]\tvalid_0's rmse: 11.5419\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's rmse: 12.7766\n",
            "[400]\tvalid_0's rmse: 12.7705\n",
            "[600]\tvalid_0's rmse: 12.7669\n",
            "[800]\tvalid_0's rmse: 12.7627\n",
            "[1000]\tvalid_0's rmse: 12.762\n",
            "Early stopping, best iteration is:\n",
            "[872]\tvalid_0's rmse: 12.7606\n",
            "\n",
            "[LightGBM] OOF: 13.0824m\n"
          ]
        }
      ],
      "source": [
        "# --- LightGBM (A1 + A2) ---\n",
        "lgb_oof_dx, lgb_oof_dy, lgb_test_dx, lgb_test_dy = run_lgbm_oof_residual_longswap(\n",
        "    X_train, y_dx, y_dy, X_test, groups, cat_cols=cat_features,\n",
        "    long_threshold=35.0, min_long_samples=200,\n",
        "    make_category_dtype=True,\n",
        "    base_params=None, fixer_params=None,\n",
        "    num_boost_round=6000, early_stopping_rounds=200, verbose_eval=200\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_oof_dx, mlp_oof_dy, mlp_test_dx, mlp_test_dy = run_mlp_pipeline(\n",
        "    X_train, y_dx, y_dy, X_test, groups, cat_features\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZY_2uSL8Wws",
        "outputId": "4c14933d-5712-4ea4-a8ce-e080196ce9b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Fold 1 Done\n",
            "MLP Fold 2 Done\n",
            "MLP Fold 3 Done\n",
            "MLP Fold 4 Done\n",
            "MLP Fold 5 Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP 단독 OOF 점수 출력\n",
        "mlp_score = metric(y_dx, y_dy, mlp_oof_dx, mlp_oof_dy)\n",
        "print(f\"✨ MLP 단독 OOF 점수: {mlp_score:.4f}m\")\n",
        "\n",
        "# 기존 부스팅 모델들과 비교\n",
        "print(f\"  - CatBoost : {cb_score_all:.4f}m\")\n",
        "print(f\"  - LightGBM : {lg_score_all:.4f}m\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep99rxJh91tO",
        "outputId": "12d3b560-c186-4c03-f339-47d6d2e25c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✨ MLP 단독 OOF 점수: 13.3885m\n",
            "  - CatBoost : 13.0940m\n",
            "  - LightGBM : 13.0824m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3중 버킷 가중치 결합 및 결과 확인\n",
        "\n",
        "# 1. 3개 모델의 OOF/TEST 데이터를 튜플로 묶기\n",
        "cb_res  = (cb_oof_dx, cb_oof_dy, cb_test_dx, cb_test_dy)\n",
        "lgb_res = (lgb_oof_dx, lgb_oof_dy, lgb_test_dx, lgb_test_dy)\n",
        "mlp_res = (mlp_oof_dx, mlp_oof_dy, mlp_test_dx, mlp_test_dy)\n",
        "\n",
        "# 2. 3중 가중치 계산 (이미 정의한 함수 호출)\n",
        "dist_true = np.sqrt(y_dx**2 + y_dy**2)\n",
        "buckets_true = np.array([bucket_from_dist(d) for d in dist_true])\n",
        "weights_triple = {}\n",
        "\n",
        "for b in [\"short\", \"mid\", \"long\"]:\n",
        "    idx = np.where(buckets_true == b)[0]\n",
        "    # 각 구간별 RMSE 계산\n",
        "    s_cb = metric(y_dx[idx], y_dy[idx], cb_res[0][idx], cb_res[1][idx])\n",
        "    s_lg = metric(y_dx[idx], y_dy[idx], lgb_res[0][idx], lgb_res[1][idx])\n",
        "    s_ml = metric(y_dx[idx], y_dy[idx], mlp_res[0][idx], mlp_res[1][idx])\n",
        "\n",
        "    # 성능 기반 가중치 (지수 alpha=0.5 적용)\n",
        "    inv_s = np.array([1/s_cb, 1/s_lg, 1/s_ml]) ** best_alpha\n",
        "\n",
        "    weights_triple[b] = inv_s / inv_s.sum()\n",
        "\n",
        "# 3. 가중치 출력 (MLP가 어느 구간에서 기여하는지 확인 가능)\n",
        "print(\"\\n[3중 앙상블 구간별 가중치 (CB, LGBM, MLP)]\")\n",
        "for b, w in weights_triple.items():\n",
        "    print(f\"  {b:5} : {w[0]:.4f}, {w[1]:.4f}, {w[2]:.4f}\")\n",
        "\n",
        "# 4. OOF 결합 및 최종 점수 확인\n",
        "ens_oof_dx = np.zeros_like(y_dx)\n",
        "ens_oof_dy = np.zeros_like(y_dy)\n",
        "\n",
        "for b in [\"short\", \"mid\", \"long\"]:\n",
        "    idx = np.where(buckets_true == b)[0]\n",
        "    w_cb, w_lg, w_ml = weights_triple[b]\n",
        "    ens_oof_dx[idx] = w_cb*cb_res[0][idx] + w_lg*lgb_res[0][idx] + w_ml*mlp_res[0][idx]\n",
        "    ens_oof_dy[idx] = w_cb*cb_res[1][idx] + w_lg*lgb_res[1][idx] + w_ml*mlp_res[1][idx]\n",
        "\n",
        "final_oof_score = metric(y_dx, y_dy, ens_oof_dx, ens_oof_dy)\n",
        "print(f\"\\n [최종 3중 앙상블 OOF 점수] : {final_oof_score:.4f}m\")\n",
        "print(f\"   (기존 2중 앙상블:12.98)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBi5bFvi9-Iu",
        "outputId": "ce04d40e-50d1-4d30-fa31-61c125757d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[3중 앙상블 구간별 가중치 (CB, LGBM, MLP)]\n",
            "  short : 0.1126, 0.3790, 0.5085\n",
            "  mid   : 0.3480, 0.5410, 0.1110\n",
            "  long  : 0.5514, 0.1961, 0.2525\n",
            "\n",
            "🔥 [최종 3중 앙상블 OOF 점수] : 12.8054m\n",
            "   (기존 2중 앙상블:12.98)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  3중 앙상블 적용 및 제출 파일 저장\n",
        "\n",
        "# 1. 테스트 데이터의 버킷 기준 거리 생성 (가장 안정적인 CB 예측값 기준)\n",
        "test_dist_ref = np.sqrt(cb_test_dx**2 + cb_test_dy**2)\n",
        "buckets_test = np.array([bucket_from_dist(d) for d in test_dist_ref])\n",
        "\n",
        "# 2. 결과 저장용 배열 초기화\n",
        "ens_test_dx = np.zeros_like(cb_test_dx, dtype=np.float32)\n",
        "ens_test_dy = np.zeros_like(cb_test_dy, dtype=np.float32)\n",
        "\n",
        "# 3. 구간별 3중 가중치 적용 (CB, LGBM, MLP 순)\n",
        "for b in [\"short\", \"mid\", \"long\"]:\n",
        "    idx = np.where(buckets_test == b)[0]\n",
        "    if len(idx) == 0: continue\n",
        "\n",
        "    # 방금 출력된 황금 비율(weights_triple) 적용\n",
        "    w_cb, w_lg, w_ml = weights_triple[b]\n",
        "\n",
        "    ens_test_dx[idx] = (w_cb * cb_test_dx[idx] +\n",
        "                        w_lg * lgb_test_dx[idx] +\n",
        "                        w_ml * mlp_test_dx[idx])\n",
        "\n",
        "    ens_test_dy[idx] = (w_cb * cb_test_dy[idx] +\n",
        "                        w_lg * lgb_test_dy[idx] +\n",
        "                        w_ml * mlp_test_dy[idx])\n",
        "\n",
        "# 4. (선택) Carry Cap 적용 - 점수 향상이 검증되었다면 사용\n",
        "if after < before:\n",
        "    print(\"Applying Carry Cap to Test set...\")\n",
        "    ens_test_dx, ens_test_dy = apply_carry_hard_caps(ens_test_dx, ens_test_dy, test_epi, caps)\n",
        "\n",
        "# 5. 최종 좌표 계산 및 Clipping\n",
        "final_pred_x = np.clip(test_epi[\"start_x\"].values + ens_test_dx, *Config.CLIP_X)\n",
        "final_pred_y = np.clip(test_epi[\"start_y\"].values + ens_test_dy, *Config.CLIP_Y)\n",
        "\n",
        "# 6. 제출 파일 저장\n",
        "submission = pd.DataFrame({\n",
        "    \"game_episode\": test_epi[\"game_episode\"].values,\n",
        "    \"end_x\": final_pred_x,\n",
        "    \"end_y\": final_pred_y\n",
        "})\n",
        "\n",
        "submission.to_csv(\"sub_triple_ensemble_final.csv\", index=False)\n",
        "print(\"\\n✅ 제출 파일 저장 완료: sub_triple_ensemble_final.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41-lqpVq_Xjq",
        "outputId": "41ba8e3f-4532-4e7e-91e3-4c3f1788711c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ 제출 파일 저장 완료: sub_triple_ensemble_final.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}